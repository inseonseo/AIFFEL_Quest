{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "922c3d9d",
   "metadata": {},
   "source": [
    "## CustomTrainerVietClassifier\n",
    "- model.fit()에서 벗어나기 PJT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f70cc882",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c62494d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training set과 test set의 모든 이미지 파일에 대해서,\n",
    "# jpg image header가 포함되지 않은 (jpg의 파일 구조에 어긋나는) 파일들을 삭제해줍니다.\n",
    "\n",
    "data_path = '/aiffel/aiffel/model-fit/data/30vnfoods/'\n",
    "train_path = data_path + 'Train/'\n",
    "test_path = data_path + 'Test/'\n",
    "\n",
    "for path in [train_path, test_path]:\n",
    "    classes = os.listdir(path)\n",
    "\n",
    "    for food in classes:\n",
    "        food_path = os.path.join(path, food)\n",
    "        images = os.listdir(food_path)\n",
    "        \n",
    "        for image in images:\n",
    "            with open(os.path.join(food_path, image), 'rb') as f:\n",
    "                bytes = f.read()\n",
    "            if bytes[:3] != b'\\xff\\xd8\\xff':\n",
    "                print(os.path.join(food_path, image))\n",
    "                os.remove(os.path.join(food_path, image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee08f69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c458dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data의 개수: 9775\n"
     ]
    }
   ],
   "source": [
    "classes = os.listdir(train_path)\n",
    "train_length = 0\n",
    "\n",
    "for food in classes:\n",
    "    food_path = os.path.join(train_path, food)\n",
    "    images = os.listdir(food_path)\n",
    "    \n",
    "    train_length += len(images)\n",
    "\n",
    "print('training data의 개수: '+str(train_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b46dee5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d5d5d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문제1: dataloader 구현하기\n",
    "\n",
    "def process_path(file_path, class_names, img_shape=(224, 224)):\n",
    "    '''\n",
    "    file_path로 부터 class label을 만들고, 이미지를 읽는 함수\n",
    "    이미지 크기를 (224, 224)로 맞춰주세요.\n",
    "    '''\n",
    "    label = tf.strings.split(file_path, os.path.sep)\n",
    "    label = label[-2] == class_names\n",
    "    label = tf.cast(label, tf.float32)\n",
    "\n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = tf.image.decode_png(img, channels=3)\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    img = tf.image.resize(img, img_shape) \n",
    "\n",
    "#     [keypoint,] = tf.py_function(process_keypoint, [file_path], [tf.float32])\n",
    "    \n",
    "    return img, label\n",
    "\n",
    "def prepare_for_training(ds, batch_size=32, cache=True, shuffle_buffer_size=1000):\n",
    "    '''\n",
    "    TensorFlow Data API를 이용해 data batch를 만드는 함수\n",
    "    '''\n",
    "    if cache:\n",
    "        if isinstance(cache, str):\n",
    "            ds = ds.cache(cache)\n",
    "        else:\n",
    "            ds = ds.cache()\n",
    "    ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n",
    "    ds = ds.repeat(2)\n",
    "    ds = ds.batch(batch_size)\n",
    "    ds = ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    return ds\n",
    "\n",
    "def load_data(data_path, batch_size=32):\n",
    "    '''\n",
    "    데이터를 만들기 위해 필요한 함수들을 호출하고 데이터를 리턴해주는 함수\n",
    "    TensorFlow Dataset 객체를 생성하고 process_path 함수로 이미지와 라벨을 묶은 다음,\n",
    "    prepare_for_training 함수로 batch가 적용된 Dataset 객체를 만들어주세요.\n",
    "    '''\n",
    "    class_names = [cls for cls in os.listdir(data_path) if cls != '.DS_Store']\n",
    "    data_path = pathlib.Path(data_path)\n",
    "\n",
    "    list_ds = tf.data.Dataset.list_files(str(data_path/'*/*'))\n",
    "    labeled_ds = list_ds.map(lambda x: process_path(x, class_names, img_shape=(224, 224)))\n",
    "    ds = prepare_for_training(labeled_ds, batch_size=batch_size)\n",
    "\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71d0171",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "430238c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "efficientnetb0 (Functional)  (None, None, None, 1280)  4049571   \n",
      "_________________________________________________________________\n",
      "sequential (Sequential)      (None, 1280)              5120      \n",
      "_________________________________________________________________\n",
      "pred (Dense)                 multiple                  6405      \n",
      "=================================================================\n",
      "Total params: 4,061,096\n",
      "Trainable params: 8,965\n",
      "Non-trainable params: 4,052,131\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 문제2: 모델 구현하기\n",
    "\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "\n",
    "class Model(tf.keras.Model):\n",
    "    '''\n",
    "    EfficientNetB0을 백본으로 사용하는 모델을 구성합니다.\n",
    "    Classification 문제로 접근할 것이기 때문에 맨 마지막 Dense 레이어에 \n",
    "    우리가 원하는 클래스 개수만큼을 지정해주어야 합니다.\n",
    "    '''\n",
    "    def __init__(self, num_classes=5, freeze=False):\n",
    "        super(Model, self).__init__()\n",
    "        self.base_model = EfficientNetB0(include_top=False, weights='imagenet')\n",
    "        if freeze:\n",
    "            self.base_model.trainable = False\n",
    "        self.top = tf.keras.Sequential([tf.keras.layers.GlobalAveragePooling2D(name=\"avg_pool\"),\n",
    "                                       tf.keras.layers.BatchNormalization(),\n",
    "                                       tf.keras.layers.Dropout(0.5, name=\"top_dropout\")])\n",
    "        self.classifier = tf.keras.layers.Dense(num_classes, activation=\"softmax\", name=\"pred\")\n",
    "    def call(self, inputs, training=True):\n",
    "        x = self.base_model(inputs)\n",
    "        x = self.top(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    model = Model(num_classes=5, freeze=True)\n",
    "    model.build(input_shape=(None, 224, 224, 3))\n",
    "    print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a9c8c1",
   "metadata": {},
   "source": [
    "- EfficientNetB0 backbone과 Dense 레이어를 결합하여 모델 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f6dd6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문제3: custom trainer 구현하기\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, model, epochs, batch, loss_fn, optimizer):\n",
    "        self.model = model\n",
    "        self.epochs = epochs\n",
    "        self.batch = batch\n",
    "        self.loss_fn = loss_fn\n",
    "        self.optimizer = optimizer\n",
    "    def train(self, train_dataset, train_metric):\n",
    "        for epoch in range(self.epochs):\n",
    "            print(\"\\nStart of epoch %d\" % (epoch+1,))\n",
    "            # 매 batch 마다 반복적으로 학습\n",
    "            for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
    "                with tf.GradientTape() as tape:\n",
    "                    logits = model(x_batch_train, training=True)\n",
    "                    loss_value = self.loss_fn(y_batch_train, logits)\n",
    "                grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "                self.optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "                # train metric 업데이트\n",
    "                train_metric.update_state(y_batch_train, logits)\n",
    "                # 5 배치마다 로깅\n",
    "                if step % 16 == 0:\n",
    "                    print(\n",
    "                        \"Training loss (for one batch) at step %d: %.4f\"\n",
    "                        % (step, float(loss_value))\n",
    "                    )\n",
    "                    print(\"Seen so far: %d samples\" % ((step + 1) * self.batch))\n",
    "                    print(train_metric.result().numpy())\n",
    "\n",
    "            # 마지막 epoch 학습이 끝나면 train 결과를 보여줌\n",
    "            train_acc = train_acc_metric.result()\n",
    "            print(\"Training acc over epoch: %.4f\" % (float(train_acc),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ad420e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8fb8193",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 1\n",
      "Training loss (for one batch) at step 0: 3.8146\n",
      "Seen so far: 32 samples\n",
      "0.125\n",
      "Training loss (for one batch) at step 16: 1.6550\n",
      "Seen so far: 544 samples\n",
      "0.3602941\n",
      "Training loss (for one batch) at step 32: 1.4073\n",
      "Seen so far: 1056 samples\n",
      "0.47916666\n",
      "Training loss (for one batch) at step 48: 0.6260\n",
      "Seen so far: 1568 samples\n",
      "0.53635204\n",
      "Training loss (for one batch) at step 64: 1.0460\n",
      "Seen so far: 2080 samples\n",
      "0.5692308\n",
      "Training loss (for one batch) at step 80: 1.1010\n",
      "Seen so far: 2592 samples\n",
      "0.5952932\n",
      "Training loss (for one batch) at step 96: 1.3434\n",
      "Seen so far: 3104 samples\n",
      "0.61533505\n",
      "Training loss (for one batch) at step 112: 0.4797\n",
      "Seen so far: 3616 samples\n",
      "0.63274336\n",
      "Training loss (for one batch) at step 128: 1.1150\n",
      "Seen so far: 4128 samples\n",
      "0.6455911\n",
      "Training loss (for one batch) at step 144: 0.4183\n",
      "Seen so far: 4640 samples\n",
      "0.6599138\n",
      "Training loss (for one batch) at step 160: 0.7884\n",
      "Seen so far: 5152 samples\n",
      "0.67177796\n",
      "Training loss (for one batch) at step 176: 0.9833\n",
      "Seen so far: 5664 samples\n",
      "0.6813206\n",
      "Training loss (for one batch) at step 192: 0.3737\n",
      "Seen so far: 6176 samples\n",
      "0.6897668\n",
      "Training loss (for one batch) at step 208: 0.4743\n",
      "Seen so far: 6688 samples\n",
      "0.69602275\n",
      "Training loss (for one batch) at step 224: 0.7285\n",
      "Seen so far: 7200 samples\n",
      "0.7058333\n",
      "Training loss (for one batch) at step 240: 0.5438\n",
      "Seen so far: 7712 samples\n",
      "0.7122666\n",
      "Training loss (for one batch) at step 256: 0.5807\n",
      "Seen so far: 8224 samples\n",
      "0.7186284\n",
      "Training loss (for one batch) at step 272: 0.3785\n",
      "Seen so far: 8736 samples\n",
      "0.7230998\n",
      "Training loss (for one batch) at step 288: 0.4462\n",
      "Seen so far: 9248 samples\n",
      "0.7301038\n",
      "Training loss (for one batch) at step 304: 0.3295\n",
      "Seen so far: 9760 samples\n",
      "0.73586065\n",
      "Training loss (for one batch) at step 320: 0.7889\n",
      "Seen so far: 10272 samples\n",
      "0.7425039\n",
      "Training loss (for one batch) at step 336: 0.7310\n",
      "Seen so far: 10784 samples\n",
      "0.7494436\n",
      "Training loss (for one batch) at step 352: 0.3083\n",
      "Seen so far: 11296 samples\n",
      "0.754869\n",
      "Training loss (for one batch) at step 368: 0.3489\n",
      "Seen so far: 11808 samples\n",
      "0.75982386\n",
      "Training loss (for one batch) at step 384: 0.7220\n",
      "Seen so far: 12320 samples\n",
      "0.7646104\n",
      "Training loss (for one batch) at step 400: 0.3218\n",
      "Seen so far: 12832 samples\n",
      "0.7687812\n",
      "Training loss (for one batch) at step 416: 0.6324\n",
      "Seen so far: 13344 samples\n",
      "0.77293164\n",
      "Training loss (for one batch) at step 432: 0.0748\n",
      "Seen so far: 13856 samples\n",
      "0.7762702\n",
      "Training loss (for one batch) at step 448: 0.2998\n",
      "Seen so far: 14368 samples\n",
      "0.7792316\n",
      "Training loss (for one batch) at step 464: 0.3657\n",
      "Seen so far: 14880 samples\n",
      "0.78178763\n",
      "Training loss (for one batch) at step 480: 0.8011\n",
      "Seen so far: 15392 samples\n",
      "0.7846284\n",
      "Training loss (for one batch) at step 496: 0.1696\n",
      "Seen so far: 15904 samples\n",
      "0.78854376\n",
      "Training loss (for one batch) at step 512: 0.2014\n",
      "Seen so far: 16416 samples\n",
      "0.7905093\n",
      "Training loss (for one batch) at step 528: 0.3829\n",
      "Seen so far: 16928 samples\n",
      "0.7937146\n",
      "Training loss (for one batch) at step 544: 0.3824\n",
      "Seen so far: 17440 samples\n",
      "0.7960436\n",
      "Training loss (for one batch) at step 560: 0.3586\n",
      "Seen so far: 17952 samples\n",
      "0.79924244\n",
      "Training loss (for one batch) at step 576: 0.2205\n",
      "Seen so far: 18464 samples\n",
      "0.8018306\n",
      "Training loss (for one batch) at step 592: 0.5601\n",
      "Seen so far: 18976 samples\n",
      "0.80369943\n",
      "Training loss (for one batch) at step 608: 0.1214\n",
      "Seen so far: 19488 samples\n",
      "0.806445\n",
      "Training acc over epoch: 0.8066\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss (for one batch) at step 0: 0.4467\n",
      "Seen so far: 32 samples\n",
      "0.8067613\n",
      "Training loss (for one batch) at step 16: 0.1490\n",
      "Seen so far: 544 samples\n",
      "0.8097442\n",
      "Training loss (for one batch) at step 32: 0.3487\n",
      "Seen so far: 1056 samples\n",
      "0.8118024\n",
      "Training loss (for one batch) at step 48: 0.1406\n",
      "Seen so far: 1568 samples\n",
      "0.81418693\n",
      "Training loss (for one batch) at step 64: 0.1873\n",
      "Seen so far: 2080 samples\n",
      "0.81622744\n",
      "Training loss (for one batch) at step 80: 0.0939\n",
      "Seen so far: 2592 samples\n",
      "0.81835425\n",
      "Training loss (for one batch) at step 96: 0.2932\n",
      "Seen so far: 3104 samples\n",
      "0.81998765\n",
      "Training loss (for one batch) at step 112: 0.4597\n",
      "Seen so far: 3616 samples\n",
      "0.8217215\n",
      "Training loss (for one batch) at step 128: 0.4728\n",
      "Seen so far: 4128 samples\n",
      "0.8235071\n",
      "Training loss (for one batch) at step 144: 0.2616\n",
      "Seen so far: 4640 samples\n",
      "0.82558906\n",
      "Training loss (for one batch) at step 160: 0.1297\n",
      "Seen so far: 5152 samples\n",
      "0.82730144\n",
      "Training loss (for one batch) at step 176: 0.2134\n",
      "Seen so far: 5664 samples\n",
      "0.82886493\n",
      "Training loss (for one batch) at step 192: 0.0833\n",
      "Seen so far: 6176 samples\n",
      "0.8311436\n",
      "Training loss (for one batch) at step 208: 0.5972\n",
      "Seen so far: 6688 samples\n",
      "0.83276165\n",
      "Training loss (for one batch) at step 224: 0.2948\n",
      "Seen so far: 7200 samples\n",
      "0.83386916\n",
      "Training loss (for one batch) at step 240: 0.5546\n",
      "Seen so far: 7712 samples\n",
      "0.8350451\n",
      "Training loss (for one batch) at step 256: 0.5074\n",
      "Seen so far: 8224 samples\n",
      "0.8365738\n",
      "Training loss (for one batch) at step 272: 0.2463\n",
      "Seen so far: 8736 samples\n",
      "0.8376936\n",
      "Training loss (for one batch) at step 288: 0.4222\n",
      "Seen so far: 9248 samples\n",
      "0.8391555\n",
      "Training loss (for one batch) at step 304: 0.0490\n",
      "Seen so far: 9760 samples\n",
      "0.8409075\n",
      "Training loss (for one batch) at step 320: 0.2479\n",
      "Seen so far: 10272 samples\n",
      "0.8423312\n",
      "Training loss (for one batch) at step 336: 0.1590\n",
      "Seen so far: 10784 samples\n",
      "0.8438386\n",
      "Training loss (for one batch) at step 352: 0.1574\n",
      "Seen so far: 11296 samples\n",
      "0.84519875\n",
      "Training loss (for one batch) at step 368: 0.0559\n",
      "Seen so far: 11808 samples\n",
      "0.84680146\n",
      "Training loss (for one batch) at step 384: 0.0556\n",
      "Seen so far: 12320 samples\n",
      "0.8479448\n",
      "Training loss (for one batch) at step 400: 0.0449\n",
      "Seen so far: 12832 samples\n",
      "0.84917545\n",
      "Training loss (for one batch) at step 416: 0.5834\n",
      "Seen so far: 13344 samples\n",
      "0.8498814\n",
      "Training loss (for one batch) at step 432: 0.1897\n",
      "Seen so far: 13856 samples\n",
      "0.85116446\n",
      "Training loss (for one batch) at step 448: 0.4577\n",
      "Seen so far: 14368 samples\n",
      "0.8518486\n",
      "Training loss (for one batch) at step 464: 0.0370\n",
      "Seen so far: 14880 samples\n",
      "0.8530932\n",
      "Training loss (for one batch) at step 480: 0.4152\n",
      "Seen so far: 15392 samples\n",
      "0.85433\n",
      "Training loss (for one batch) at step 496: 0.1261\n",
      "Seen so far: 15904 samples\n",
      "0.8553619\n",
      "Training loss (for one batch) at step 512: 0.2047\n",
      "Seen so far: 16416 samples\n",
      "0.85653114\n",
      "Training loss (for one batch) at step 528: 0.0476\n",
      "Seen so far: 16928 samples\n",
      "0.8573661\n",
      "Training loss (for one batch) at step 544: 0.4570\n",
      "Seen so far: 17440 samples\n",
      "0.8580427\n",
      "Training loss (for one batch) at step 560: 0.1040\n",
      "Seen so far: 17952 samples\n",
      "0.8589942\n",
      "Training loss (for one batch) at step 576: 0.0793\n",
      "Seen so far: 18464 samples\n",
      "0.8601305\n",
      "Training loss (for one batch) at step 592: 0.0593\n",
      "Seen so far: 18976 samples\n",
      "0.86089915\n",
      "Training loss (for one batch) at step 608: 0.2225\n",
      "Seen so far: 19488 samples\n",
      "0.8619038\n",
      "Training acc over epoch: 0.8619\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss (for one batch) at step 0: 0.2540\n",
      "Seen so far: 32 samples\n",
      "0.86187774\n",
      "Training loss (for one batch) at step 16: 0.6717\n",
      "Seen so far: 544 samples\n",
      "0.8627535\n",
      "Training loss (for one batch) at step 32: 0.0235\n",
      "Seen so far: 1056 samples\n",
      "0.86383104\n",
      "Training loss (for one batch) at step 48: 0.6425\n",
      "Seen so far: 1568 samples\n",
      "0.8647094\n",
      "Training loss (for one batch) at step 64: 0.1092\n",
      "Seen so far: 2080 samples\n",
      "0.8654687\n",
      "Training loss (for one batch) at step 80: 0.1633\n",
      "Seen so far: 2592 samples\n",
      "0.86618537\n",
      "Training loss (for one batch) at step 96: 0.2217\n",
      "Seen so far: 3104 samples\n",
      "0.8671453\n",
      "Training loss (for one batch) at step 112: 0.1129\n",
      "Seen so far: 3616 samples\n",
      "0.86789495\n",
      "Training loss (for one batch) at step 128: 0.3311\n",
      "Seen so far: 4128 samples\n",
      "0.8686037\n",
      "Training loss (for one batch) at step 144: 0.1053\n",
      "Seen so far: 4640 samples\n",
      "0.8692501\n",
      "Training loss (for one batch) at step 160: 0.1377\n",
      "Seen so far: 5152 samples\n",
      "0.8699494\n",
      "Training loss (for one batch) at step 176: 0.5861\n",
      "Seen so far: 5664 samples\n",
      "0.870655\n",
      "Training loss (for one batch) at step 192: 0.4290\n",
      "Seen so far: 6176 samples\n",
      "0.8711238\n",
      "Training loss (for one batch) at step 208: 0.3366\n",
      "Seen so far: 6688 samples\n",
      "0.8715602\n",
      "Training loss (for one batch) at step 224: 0.0626\n",
      "Seen so far: 7200 samples\n",
      "0.8722462\n",
      "Training loss (for one batch) at step 240: 0.1634\n",
      "Seen so far: 7712 samples\n",
      "0.8729599\n",
      "Training loss (for one batch) at step 256: 0.5009\n",
      "Seen so far: 8224 samples\n",
      "0.8736582\n",
      "Training loss (for one batch) at step 272: 0.3260\n",
      "Seen so far: 8736 samples\n",
      "0.8744042\n",
      "Training loss (for one batch) at step 288: 0.3460\n",
      "Seen so far: 9248 samples\n",
      "0.87513447\n",
      "Training loss (for one batch) at step 304: 0.2815\n",
      "Seen so far: 9760 samples\n",
      "0.875788\n",
      "Training loss (for one batch) at step 320: 0.1473\n",
      "Seen so far: 10272 samples\n",
      "0.87620515\n",
      "Training loss (for one batch) at step 336: 0.0245\n",
      "Seen so far: 10784 samples\n",
      "0.87693447\n",
      "Training loss (for one batch) at step 352: 0.1547\n",
      "Seen so far: 11296 samples\n",
      "0.87766886\n",
      "Training loss (for one batch) at step 368: 0.0982\n",
      "Seen so far: 11808 samples\n",
      "0.8782706\n",
      "Training loss (for one batch) at step 384: 0.0344\n",
      "Seen so far: 12320 samples\n",
      "0.87876314\n",
      "Training loss (for one batch) at step 400: 0.0491\n",
      "Seen so far: 12832 samples\n",
      "0.8795733\n",
      "Training loss (for one batch) at step 416: 0.1923\n",
      "Seen so far: 13344 samples\n",
      "0.88017696\n",
      "Training loss (for one batch) at step 432: 0.1113\n",
      "Seen so far: 13856 samples\n",
      "0.88067454\n",
      "Training loss (for one batch) at step 448: 0.1074\n",
      "Seen so far: 14368 samples\n",
      "0.88118124\n",
      "Training loss (for one batch) at step 464: 0.0215\n",
      "Seen so far: 14880 samples\n",
      "0.8817525\n",
      "Training loss (for one batch) at step 480: 0.2661\n",
      "Seen so far: 15392 samples\n",
      "0.8822396\n",
      "Training loss (for one batch) at step 496: 0.5135\n",
      "Seen so far: 15904 samples\n",
      "0.8824631\n",
      "Training loss (for one batch) at step 512: 0.1218\n",
      "Seen so far: 16416 samples\n",
      "0.88284457\n",
      "Training loss (for one batch) at step 528: 0.1739\n",
      "Seen so far: 16928 samples\n",
      "0.88334405\n",
      "Training loss (for one batch) at step 544: 0.2658\n",
      "Seen so far: 17440 samples\n",
      "0.8839759\n",
      "Training loss (for one batch) at step 560: 0.1576\n",
      "Seen so far: 17952 samples\n",
      "0.88436866\n",
      "Training loss (for one batch) at step 576: 0.3018\n",
      "Seen so far: 18464 samples\n",
      "0.8847891\n",
      "Training loss (for one batch) at step 592: 0.1254\n",
      "Seen so far: 18976 samples\n",
      "0.88530546\n",
      "Training loss (for one batch) at step 608: 0.1343\n",
      "Seen so far: 19488 samples\n",
      "0.88577867\n",
      "Training acc over epoch: 0.8858\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss (for one batch) at step 0: 0.1507\n",
      "Seen so far: 32 samples\n",
      "0.8858423\n",
      "Training loss (for one batch) at step 16: 0.0629\n",
      "Seen so far: 544 samples\n",
      "0.8864412\n",
      "Training loss (for one batch) at step 32: 0.1184\n",
      "Seen so far: 1056 samples\n",
      "0.88713026\n",
      "Training loss (for one batch) at step 48: 0.0623\n",
      "Seen so far: 1568 samples\n",
      "0.88760835\n",
      "Training loss (for one batch) at step 64: 0.2339\n",
      "Seen so far: 2080 samples\n",
      "0.88817716\n",
      "Training loss (for one batch) at step 80: 0.1591\n",
      "Seen so far: 2592 samples\n",
      "0.8887365\n",
      "Training loss (for one batch) at step 96: 0.5013\n",
      "Seen so far: 3104 samples\n",
      "0.8892217\n",
      "Training loss (for one batch) at step 112: 0.1034\n",
      "Seen so far: 3616 samples\n",
      "0.8897633\n",
      "Training loss (for one batch) at step 128: 0.2516\n",
      "Seen so far: 4128 samples\n",
      "0.89007294\n",
      "Training loss (for one batch) at step 144: 0.1270\n",
      "Seen so far: 4640 samples\n",
      "0.89059883\n",
      "Training loss (for one batch) at step 160: 0.0480\n",
      "Seen so far: 5152 samples\n",
      "0.89106923\n",
      "Training loss (for one batch) at step 176: 0.0876\n",
      "Seen so far: 5664 samples\n",
      "0.89159435\n",
      "Training loss (for one batch) at step 192: 0.0101\n",
      "Seen so far: 6176 samples\n",
      "0.8921729\n",
      "Training loss (for one batch) at step 208: 0.2243\n",
      "Seen so far: 6688 samples\n",
      "0.89258933\n",
      "Training loss (for one batch) at step 224: 0.2262\n",
      "Seen so far: 7200 samples\n",
      "0.89298403\n",
      "Training loss (for one batch) at step 240: 0.2330\n",
      "Seen so far: 7712 samples\n",
      "0.8934029\n",
      "Training loss (for one batch) at step 256: 0.1465\n",
      "Seen so far: 8224 samples\n",
      "0.89389\n",
      "Training loss (for one batch) at step 272: 0.1278\n",
      "Seen so far: 8736 samples\n",
      "0.89425105\n",
      "Training loss (for one batch) at step 288: 0.2839\n",
      "Seen so far: 9248 samples\n",
      "0.8947097\n",
      "Training loss (for one batch) at step 304: 0.0524\n",
      "Seen so far: 9760 samples\n",
      "0.89524925\n",
      "Training loss (for one batch) at step 320: 0.0092\n",
      "Seen so far: 10272 samples\n",
      "0.89565015\n",
      "Training loss (for one batch) at step 336: 0.3164\n",
      "Seen so far: 10784 samples\n",
      "0.896074\n",
      "Training loss (for one batch) at step 352: 0.2475\n",
      "Seen so far: 11296 samples\n",
      "0.8965202\n",
      "Training loss (for one batch) at step 368: 0.3435\n",
      "Seen so far: 11808 samples\n",
      "0.896818\n",
      "Training loss (for one batch) at step 384: 0.1986\n",
      "Seen so far: 12320 samples\n",
      "0.8972242\n",
      "Training loss (for one batch) at step 400: 0.0045\n",
      "Seen so far: 12832 samples\n",
      "0.8974707\n",
      "Training loss (for one batch) at step 416: 0.1367\n",
      "Seen so far: 13344 samples\n",
      "0.89768595\n",
      "Training loss (for one batch) at step 432: 0.1120\n",
      "Seen so far: 13856 samples\n",
      "0.8980912\n",
      "Training loss (for one batch) at step 448: 0.0458\n",
      "Seen so far: 14368 samples\n",
      "0.8985045\n",
      "Training loss (for one batch) at step 464: 0.1354\n",
      "Seen so far: 14880 samples\n",
      "0.8987488\n",
      "Training loss (for one batch) at step 480: 0.0953\n",
      "Seen so far: 15392 samples\n",
      "0.8990843\n",
      "Training loss (for one batch) at step 496: 0.1071\n",
      "Seen so far: 15904 samples\n",
      "0.8993213\n",
      "Training loss (for one batch) at step 512: 0.2230\n",
      "Seen so far: 16416 samples\n",
      "0.899635\n",
      "Training loss (for one batch) at step 528: 0.3051\n",
      "Seen so far: 16928 samples\n",
      "0.89991796\n",
      "Training loss (for one batch) at step 544: 0.1238\n",
      "Seen so far: 17440 samples\n",
      "0.900184\n",
      "Training loss (for one batch) at step 560: 0.0801\n",
      "Seen so far: 17952 samples\n",
      "0.9004595\n",
      "Training loss (for one batch) at step 576: 0.1725\n",
      "Seen so far: 18464 samples\n",
      "0.9007314\n",
      "Training loss (for one batch) at step 592: 0.1410\n",
      "Seen so far: 18976 samples\n",
      "0.90099967\n",
      "Training loss (for one batch) at step 608: 0.1500\n",
      "Seen so far: 19488 samples\n",
      "0.90127724\n",
      "Training acc over epoch: 0.9013\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss (for one batch) at step 0: 0.1179\n",
      "Seen so far: 32 samples\n",
      "0.90131915\n",
      "Training loss (for one batch) at step 16: 0.1355\n",
      "Seen so far: 544 samples\n",
      "0.9014909\n",
      "Training loss (for one batch) at step 32: 0.2085\n",
      "Seen so far: 1056 samples\n",
      "0.9016983\n",
      "Training loss (for one batch) at step 48: 0.1639\n",
      "Seen so far: 1568 samples\n",
      "0.90197825\n",
      "Training loss (for one batch) at step 64: 0.4561\n",
      "Seen so far: 2080 samples\n",
      "0.9022421\n",
      "Training loss (for one batch) at step 80: 0.1235\n",
      "Seen so far: 2592 samples\n",
      "0.90265125\n",
      "Training loss (for one batch) at step 96: 0.2893\n",
      "Seen so far: 3104 samples\n",
      "0.9028461\n",
      "Training loss (for one batch) at step 112: 0.0485\n",
      "Seen so far: 3616 samples\n",
      "0.9031974\n",
      "Training loss (for one batch) at step 128: 0.3332\n",
      "Seen so far: 4128 samples\n",
      "0.9034472\n",
      "Training loss (for one batch) at step 144: 0.1008\n",
      "Seen so far: 4640 samples\n",
      "0.90375423\n",
      "Training loss (for one batch) at step 160: 0.0279\n",
      "Seen so far: 5152 samples\n",
      "0.9040095\n",
      "Training loss (for one batch) at step 176: 0.2775\n",
      "Seen so far: 5664 samples\n",
      "0.9043809\n",
      "Training loss (for one batch) at step 192: 0.4229\n",
      "Seen so far: 6176 samples\n",
      "0.90460557\n",
      "Training loss (for one batch) at step 208: 0.1155\n",
      "Seen so far: 6688 samples\n",
      "0.90491\n",
      "Training loss (for one batch) at step 224: 0.1933\n",
      "Seen so far: 7200 samples\n",
      "0.9052693\n",
      "Training loss (for one batch) at step 240: 0.2651\n",
      "Seen so far: 7712 samples\n",
      "0.9055196\n",
      "Training loss (for one batch) at step 256: 0.0073\n",
      "Seen so far: 8224 samples\n",
      "0.90577847\n",
      "Training loss (for one batch) at step 272: 0.0207\n",
      "Seen so far: 8736 samples\n",
      "0.9061378\n",
      "Training loss (for one batch) at step 288: 0.1344\n",
      "Seen so far: 9248 samples\n",
      "0.9065273\n",
      "Training loss (for one batch) at step 304: 0.2406\n",
      "Seen so far: 9760 samples\n",
      "0.906844\n",
      "Training loss (for one batch) at step 320: 0.0279\n",
      "Seen so far: 10272 samples\n",
      "0.90714574\n",
      "Training loss (for one batch) at step 336: 0.0607\n",
      "Seen so far: 10784 samples\n",
      "0.90745527\n",
      "Training loss (for one batch) at step 352: 0.0326\n",
      "Seen so far: 11296 samples\n",
      "0.9077612\n",
      "Training loss (for one batch) at step 368: 0.0207\n",
      "Seen so far: 11808 samples\n",
      "0.90808594\n",
      "Training loss (for one batch) at step 384: 0.1345\n",
      "Seen so far: 12320 samples\n",
      "0.90837383\n",
      "Training loss (for one batch) at step 400: 0.0154\n",
      "Seen so far: 12832 samples\n",
      "0.90868044\n",
      "Training loss (for one batch) at step 416: 0.1942\n",
      "Seen so far: 13344 samples\n",
      "0.90889627\n",
      "Training loss (for one batch) at step 432: 0.1794\n",
      "Seen so far: 13856 samples\n",
      "0.9090988\n",
      "Training loss (for one batch) at step 448: 0.6041\n",
      "Seen so far: 14368 samples\n",
      "0.9092343\n",
      "Training loss (for one batch) at step 464: 0.1425\n",
      "Seen so far: 14880 samples\n",
      "0.9095187\n",
      "Training loss (for one batch) at step 480: 0.0931\n",
      "Seen so far: 15392 samples\n",
      "0.90960765\n",
      "Training loss (for one batch) at step 496: 0.3836\n",
      "Seen so far: 15904 samples\n",
      "0.9097913\n",
      "Training loss (for one batch) at step 512: 0.2416\n",
      "Seen so far: 16416 samples\n",
      "0.9099835\n",
      "Training loss (for one batch) at step 528: 0.0660\n",
      "Seen so far: 16928 samples\n",
      "0.91021574\n",
      "Training loss (for one batch) at step 544: 0.0168\n",
      "Seen so far: 17440 samples\n",
      "0.9104454\n",
      "Training loss (for one batch) at step 560: 0.1867\n",
      "Seen so far: 17952 samples\n",
      "0.91061026\n",
      "Training loss (for one batch) at step 576: 0.1316\n",
      "Seen so far: 18464 samples\n",
      "0.9109286\n",
      "Training loss (for one batch) at step 592: 0.0693\n",
      "Seen so far: 18976 samples\n",
      "0.911295\n",
      "Training loss (for one batch) at step 608: 0.0184\n",
      "Seen so far: 19488 samples\n",
      "0.91161656\n",
      "Training acc over epoch: 0.9116\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습 코드\n",
    "\n",
    "train_path = \"/aiffel/aiffel/model-fit/data/30vnfoods/Train\"\n",
    "\n",
    "epoch = 5\n",
    "batch = 32\n",
    "\n",
    "model = Model(num_classes=10)\n",
    "dataset = load_data(data_path=train_path, batch_size=batch)\n",
    "loss_function = tf.keras.losses.CategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "train_acc_metric = tf.keras.metrics.CategoricalAccuracy()\n",
    "trainer = Trainer(model=model,\n",
    "                epochs=epoch,\n",
    "                batch=batch,\n",
    "#                 ds_length=train_length,\n",
    "                loss_fn=loss_function,\n",
    "                optimizer=optimizer)\n",
    "\n",
    "trainer.train(train_dataset=dataset,\n",
    "            train_metric=train_acc_metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f896f95",
   "metadata": {},
   "source": [
    "- 학습이 진행되면서 training accuracy가 점차 증가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97e8c6d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/32\n",
      "27/32\n",
      "26/32\n",
      "31/32\n",
      "29/32\n",
      "29/32\n",
      "30/32\n",
      "27/32\n",
      "26/32\n",
      "29/32\n"
     ]
    }
   ],
   "source": [
    "# 모델 테스트 코드\n",
    "\n",
    "test_ds = load_data(data_path=test_path)\n",
    "\n",
    "for step_train, (x_batch_train, y_batch_train) in enumerate(test_ds.take(10)):\n",
    "    prediction = model(x_batch_train)\n",
    "    print(\"{}/{}\".format(np.array(tf.equal(tf.argmax(y_batch_train, axis=1), tf.argmax(prediction, axis=1))).sum(), tf.argmax(y_batch_train, axis=1).shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2545cf8a",
   "metadata": {},
   "source": [
    "- 커스텀 데이터를 커스텀 트레이너로 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de07b1c",
   "metadata": {},
   "source": [
    "### 회고\n",
    "\n",
    "#### 문제 해결\n",
    "- JPEG 파일의 유효성 검증을 통해 데이터 품질 보장하여 훈련 과정 중에 발생할 수 있는 예기치 않은 오류 미연 방지\n",
    "- 데이터 로더 구현에서 TensorFlow의 Data API를 활용하여 효율적으로 대용량 데이터를 처리할 수 있는 파이프라인을 구축. AUTOTUNE을 활용한 프리패치 기능으로 학습 속도 향상\n",
    "- 모델 구성에서 EfficientNetB0 사용하여 특성 추출 기능 활용하고, 최종 출력 레이어를 커스터마이징하여 문제에 적합하게 조정\n",
    "\n",
    "#### 배운 점:\n",
    "- TensorFlow Data API를 활용한 데이터 전처리 및 모델 공급 방법 학습\n",
    "- EfficientNetB0을 백본으로 사용한 transfer learning 수행 방법 습득\n",
    "- Custom trainer 구현을 통한 학습 loop 내부 동작 이해\n",
    "\n",
    "#### 발전시킬 점: \n",
    "- 큰 데이터셋 처리를 위해 tf.data.Dataset의 from_generator()나 from_tensor_slices()를 활용한 lazy loading 적용\n",
    "- Adam이나 RMSProp 등 발전된 optimizer 적용 고려\n",
    "- 정확도 개선을 위한 데이터 확장(augmentation) 기법 적용\n",
    "- 보다 깊은 backbone 네트워크 사용 검토\n",
    "- Learning rate scheduler 도입을 통한 학습률 최적화 시도\n",
    "\n",
    "#### 결과 해석:\n",
    "- 테스트 결과 준수한 성능이 나왔으나, 실제 서비스 활용을 위해서는 정확도 개선을 더 진행할 수 있을 것으로 보임\n",
    "- 10개의 테스트 배치에서 평균적으로 배치당 정답 개수가 전체 개수 평균 정확도: 87.81%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
